"""
å®¿æ³Šæ–½è¨­å‘ã‘å–¶æ¥­ãƒªã‚¹ãƒˆä½œæˆã‚¢ãƒ—ãƒª

CSVã«è¨˜è¼‰ã•ã‚ŒãŸå®¿æ³Šæ–½è¨­ã®å±‹å·ã‚’ã‚‚ã¨ã«ã€
ã€Œè‡ªç¤¾HPãŒå­˜åœ¨ã—ãªã„æ–½è¨­ã®ã¿ã€ã‚’æŠ½å‡ºã—ã€å–¶æ¥­ç”¨ãƒªã‚¹ãƒˆã¨ã—ã¦CSVå‡ºåŠ›ã™ã‚‹
"""

import os
import csv
import time
import requests
from urllib.parse import urlparse
from dotenv import load_dotenv
from typing import Optional, List, Dict

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()
API_KEY = os.getenv('BRAVE_API_KEY')
SEARCH_ENDPOINT = 'https://api.search.brave.com/res/v1/web/search'

# OTAãƒ‰ãƒ¡ã‚¤ãƒ³ãƒªã‚¹ãƒˆ
OTA_DOMAINS = [
    'rakuten.co.jp',
    'jalan.net',
    'booking.com',
    'agoda.com',
    'ikyu.com',
]

# SNSãƒ‰ãƒ¡ã‚¤ãƒ³ãƒªã‚¹ãƒˆ
SNS_DOMAINS = [
    'instagram.com',
    'facebook.com',
    'twitter.com',
    'x.com',
    'ameblo.jp',
    'fc2.com',
    'jimdo.com',
    'wixsite.com',
    'google.com',
]

# APIå‘¼ã³å‡ºã—é–“éš”ï¼ˆç§’ï¼‰
API_DELAY = 1.0


def search_official_site(facility_name: str) -> Optional[dict]:
    """
    Brave Search APIã‚’ä½¿ç”¨ã—ã¦å…¬å¼ã‚µã‚¤ãƒˆã‚’æ¤œç´¢
    
    Args:
        facility_name: æ–½è¨­åï¼ˆå±‹å·ï¼‰
        
    Returns:
        APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®JSONãƒ‡ãƒ¼ã‚¿ã€ã‚¨ãƒ©ãƒ¼æ™‚ã¯None
    """
    if not API_KEY:
        print("âš ï¸  APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return None
    
    query = f"{facility_name} å…¬å¼ã‚µã‚¤ãƒˆ"
    
    headers = {
        'Accept': 'application/json',
        'X-Subscription-Token': API_KEY
    }
    params = {
        'q': query,
        'count': 10
    }
    
    try:
        response = requests.get(SEARCH_ENDPOINT, headers=headers, params=params, timeout=10)
        
        if response.status_code != 200:
            print(f"âš ï¸  APIã‚¨ãƒ©ãƒ¼ ({response.status_code}): {facility_name}")
            return None
        
        return response.json()
    except Exception as e:
        print(f"âš ï¸  æ¤œç´¢ã‚¨ãƒ©ãƒ¼ ({facility_name}): {e}")
        return None


def extract_domain(url: str) -> str:
    """
    URLã‹ã‚‰ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’æŠ½å‡º
    
    Args:
        url: URLæ–‡å­—åˆ—
        
    Returns:
        ãƒ‰ãƒ¡ã‚¤ãƒ³åï¼ˆwww.ã‚’é™¤å»ã€å°æ–‡å­—åŒ–ï¼‰
    """
    try:
        parsed = urlparse(url)
        domain = parsed.netloc.replace('www.', '').lower()
        return domain
    except Exception:
        return ''


def is_ota_domain(url: str) -> bool:
    """
    OTAãƒ‰ãƒ¡ã‚¤ãƒ³ã‹ã©ã†ã‹ã‚’åˆ¤å®š
    
    Args:
        url: URLæ–‡å­—åˆ—
        
    Returns:
        OTAãƒ‰ãƒ¡ã‚¤ãƒ³ã®å ´åˆTrue
    """
    domain = extract_domain(url)
    return any(ota_domain in domain for ota_domain in OTA_DOMAINS)


def is_sns_domain(url: str) -> bool:
    """
    SNSãƒ‰ãƒ¡ã‚¤ãƒ³ã‹ã©ã†ã‹ã‚’åˆ¤å®š
    
    Args:
        url: URLæ–‡å­—åˆ—
        
    Returns:
        SNSãƒ‰ãƒ¡ã‚¤ãƒ³ã®å ´åˆTrue
    """
    domain = extract_domain(url)
    return any(sns_domain in domain for sns_domain in SNS_DOMAINS)


def judge_hp_existence(search_results: Optional[dict], website_url: str) -> str:
    """
    HPæœ‰ç„¡ã‚’åˆ¤å®š
    
    åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯:
    - æ¤œç´¢çµæœãŒOTAã®ã¿ â†’ HPãªã—
    - Googleãƒãƒƒãƒ—ã®website_urlãŒç©ºæ¬„ â†’ HPãªã—
    - SNSãƒ‰ãƒ¡ã‚¤ãƒ³ã®ã¿ â†’ HPãªã—
    - ä¸Šè¨˜ä»¥å¤–ã®ç‹¬è‡ªãƒ‰ãƒ¡ã‚¤ãƒ³ãŒå­˜åœ¨ â†’ HPã‚ã‚Š
    
    Args:
        search_results: Brave Search APIã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹
        website_url: Googleãƒãƒƒãƒ—æ²è¼‰URL
        
    Returns:
        'ã‚ã‚Š' ã¾ãŸã¯ 'ãªã—'
    """
    # Googleãƒãƒƒãƒ—ã®website_urlãŒç©ºæ¬„ã®å ´åˆã¯HPãªã—
    if not website_url or website_url.strip() == '':
        return 'ãªã—'
    
    # æ¤œç´¢çµæœãŒãªã„å ´åˆã¯åˆ¤å®šä¸èƒ½ã ãŒã€website_urlãŒç©ºæ¬„ãªã®ã§HPãªã—
    if not search_results:
        return 'ãªã—'
    
    # APIãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ ã®ç¢ºèª
    if 'web' not in search_results:
        return 'ãªã—'
    
    if 'results' not in search_results['web'] or not search_results['web']['results']:
        return 'ãªã—'
    
    results = search_results['web']['results']
    
    # æ¤œç´¢çµæœã‚’åˆ†é¡
    ota_only = True  # OTAã®ã¿ã‹ã©ã†ã‹ã®ãƒ•ãƒ©ã‚°
    has_official_domain = False  # ç‹¬è‡ªãƒ‰ãƒ¡ã‚¤ãƒ³ãŒå­˜åœ¨ã™ã‚‹ã‹
    
    for result in results:
        url = result.get('url', '')
        if not url:
            continue
        
        # OTAãƒ‰ãƒ¡ã‚¤ãƒ³ã‹ãƒã‚§ãƒƒã‚¯
        if is_ota_domain(url):
            continue  # OTAãƒ‰ãƒ¡ã‚¤ãƒ³ã¯ã‚¹ã‚­ãƒƒãƒ—
        
        # SNSãƒ‰ãƒ¡ã‚¤ãƒ³ã‹ãƒã‚§ãƒƒã‚¯
        if is_sns_domain(url):
            continue  # SNSãƒ‰ãƒ¡ã‚¤ãƒ³ã‚‚ã‚¹ã‚­ãƒƒãƒ—
        
        # OTAã§ã‚‚SNSã§ã‚‚ãªã„ç‹¬è‡ªãƒ‰ãƒ¡ã‚¤ãƒ³ãŒè¦‹ã¤ã‹ã£ãŸ
        ota_only = False
        has_official_domain = True
        break  # 1ã¤ã§ã‚‚è¦‹ã¤ã‹ã‚Œã°ååˆ†
    
    # åˆ¤å®šçµæœ
    if ota_only:
        # OTAã®ã¿ã®å ´åˆã¯HPãªã—
        return 'ãªã—'
    elif has_official_domain:
        # ç‹¬è‡ªãƒ‰ãƒ¡ã‚¤ãƒ³ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯HPã‚ã‚Š
        return 'ã‚ã‚Š'
    else:
        # æ¤œç´¢çµæœãŒãªã„å ´åˆã‚‚HPãªã—
        return 'ãªã—'


def load_csv(input_file: str) -> List[Dict[str, str]]:
    """
    CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    
    Args:
        input_file: å…¥åŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        
    Returns:
        æ–½è¨­ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
    """
    facilities = []
    
    try:
        with open(input_file, 'r', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f)
            for row in reader:
                facilities.append({
                    'facility_name': row.get('facility_name', '').strip(),
                    'phone_number': row.get('phone_number', '').strip(),
                    'website_url': row.get('website_url', '').strip(),
                })
        
        print(f"âœ… {len(facilities)}ä»¶ã®æ–½è¨­ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        return facilities
    except FileNotFoundError:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_file}")
        return []
    except Exception as e:
        print(f"âŒ CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return []


def save_csv(facilities: List[Dict[str, str]], output_file: str):
    """
    CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    
    Args:
        facilities: æ–½è¨­ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
        output_file: å‡ºåŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    """
    try:
        with open(output_file, 'w', encoding='utf-8-sig', newline='') as f:
            fieldnames = ['facility_name', 'phone_number', 'hp_status', 'memo']
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            
            writer.writeheader()
            for facility in facilities:
                writer.writerow({
                    'facility_name': facility['facility_name'],
                    'phone_number': facility['phone_number'],
                    'hp_status': 'ãªã—',
                    'memo': 'å…¬å¼HPæœªä¿æœ‰'
                })
        
        print(f"âœ… çµæœã‚’ {output_file} ã«ä¿å­˜ã—ã¾ã—ãŸ")
    except Exception as e:
        print(f"âŒ CSVä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    input_file = 'input.csv'
    output_file = 'output.csv'
    
    # APIã‚­ãƒ¼ã®ç¢ºèª
    if not API_KEY:
        print("âŒ ã‚¨ãƒ©ãƒ¼: BRAVE_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return
    
    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    facilities = load_csv(input_file)
    if not facilities:
        return
    
    # HPãªã—ã®æ–½è¨­ã®ã¿ã‚’æŠ½å‡º
    no_hp_facilities = []
    total_count = len(facilities)
    
    print(f"\nğŸ” {total_count}ä»¶ã®æ–½è¨­ã«ã¤ã„ã¦HPæœ‰ç„¡ã‚’åˆ¤å®šã—ã¾ã™...\n")
    
    for i, facility in enumerate(facilities, 1):
        facility_name = facility['facility_name']
        website_url = facility['website_url']
        
        print(f"[{i}/{total_count}] å‡¦ç†ä¸­: {facility_name}")
        
        try:
            # å…¬å¼ã‚µã‚¤ãƒˆã‚’æ¤œç´¢
            search_results = search_official_site(facility_name)
            
            # HPæœ‰ç„¡ã‚’åˆ¤å®š
            hp_status = judge_hp_existence(search_results, website_url)
            
            # HPãªã—ã®æ–½è¨­ã®ã¿ã‚’æŠ½å‡º
            if hp_status == 'ãªã—':
                no_hp_facilities.append(facility)
                print(f"  â†’ HPãªã—ï¼ˆæŠ½å‡ºå¯¾è±¡ï¼‰")
            else:
                print(f"  â†’ HPã‚ã‚Šï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")
            
        except Exception as e:
            print(f"  âš ï¸  ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼ãŒèµ·ãã¦ã‚‚å‡¦ç†ã‚’ç¶šã‘ã‚‹ï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ã¯HPãªã—ã¨ã—ã¦æ‰±ã†ï¼‰
            no_hp_facilities.append(facility)
        
        # APIå‘¼ã³å‡ºã—é–“éš”ã‚’ç©ºã‘ã‚‹ï¼ˆæœ€å¾Œã®1ä»¶ã¯ä¸è¦ï¼‰
        if i < total_count:
            time.sleep(API_DELAY)
    
    print(f"\nğŸ“Š æŠ½å‡ºçµæœ:")
    print(f"   HPãªã—ï¼ˆæŠ½å‡ºå¯¾è±¡ï¼‰: {len(no_hp_facilities)}ä»¶")
    print(f"   HPã‚ã‚Šï¼ˆé™¤å¤–ï¼‰: {total_count - len(no_hp_facilities)}ä»¶")
    
    # çµæœã‚’CSVã«ä¿å­˜
    if no_hp_facilities:
        save_csv(no_hp_facilities, output_file)
        print(f"\nâœ¨ å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print(f"   å…¥åŠ›: {input_file}")
        print(f"   å‡ºåŠ›: {output_file}")
    else:
        print(f"\nâš ï¸  HPãªã—ã®æ–½è¨­ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")


if __name__ == '__main__':
    main()

