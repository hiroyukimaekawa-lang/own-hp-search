"""
Streamlitã‚¢ãƒ—ãƒª: å®¿æ³Šæ–½è¨­ã®å…¬å¼ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸æ¤œç´¢ãƒ„ãƒ¼ãƒ«
"""

import os
import time
import pandas as pd
import requests
from urllib.parse import urlparse
import streamlit as st
from io import BytesIO
import csv

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="å®¿æ³Šæ–½è¨­HPæ¤œç´¢ãƒ„ãƒ¼ãƒ«",
    page_icon="ğŸ¨",
    layout="wide"
)

# OTAãƒ‰ãƒ¡ã‚¤ãƒ³ãƒªã‚¹ãƒˆ
OTA_DOMAINS = [
    'jalan.net',
    'rakuten.co.jp',
    'booking.com',
    'agoda.com',
    'ikyu.com',
    'expedia.com',
    'expedia.co.jp',
]

# SNSãƒ»ãã®ä»–é™¤å¤–ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒªã‚¹ãƒˆï¼ˆèˆªç©ºä¼šç¤¾ã€äºˆç´„ã‚µã‚¤ãƒˆãªã©ï¼‰
EXCLUDED_DOMAINS = [
    'instagram.com',
    'facebook.com',
    'twitter.com',
    'x.com',
    'ameblo.jp',
    'fc2.com',
    'jimdo.com',
    'wixsite.com',
    'google.com',
    'jal.co.jp',  # JALäºˆç´„ã‚µã‚¤ãƒˆ
    'ana.co.jp',  # ANAäºˆç´„ã‚µã‚¤ãƒˆ
    'japanican.com',  # ã‚¸ãƒ£ãƒ‘ãƒ‹ã‚«ãƒ³
    'relux.com',  # ã‚‹ã‚‹ã¶ãƒˆãƒ©ãƒ™ãƒ«
    'yadoplace.com',  # ã‚„ã©ã·ã‚‰
]

# æ¤œç´¢ã‚¯ã‚¨ãƒªã®ãƒ‘ã‚¿ãƒ¼ãƒ³
SEARCH_QUERIES = [
    lambda name: f"{name} å…¬å¼ã‚µã‚¤ãƒˆ",
    lambda name: f"{name} å®¿",
    lambda name: f"{name} ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸",
]


def extract_domain(url: str) -> str:
    """URLã‹ã‚‰ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’æŠ½å‡º"""
    try:
        parsed = urlparse(url)
        return parsed.netloc.replace('www.', '').lower()
    except Exception:
        return ''


def is_ota_domain(url: str) -> bool:
    """OTAãƒ‰ãƒ¡ã‚¤ãƒ³ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
    domain = extract_domain(url)
    return any(ota_domain in domain for ota_domain in OTA_DOMAINS)


def is_excluded_domain(url: str) -> bool:
    """é™¤å¤–ãƒ‰ãƒ¡ã‚¤ãƒ³ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
    domain = extract_domain(url)
    return any(excluded in domain for excluded in EXCLUDED_DOMAINS)


def search_brave_api(query: str, api_key: str):
    """Brave Search APIã§æ¤œç´¢ã‚’å®Ÿè¡Œ"""
    headers = {
        'Accept': 'application/json',
        'X-Subscription-Token': api_key
    }
    params = {
        'q': query,
        'count': 10
    }
    
    try:
        response = requests.get(
            'https://api.search.brave.com/res/v1/web/search',
            headers=headers,
            params=params,
            timeout=10
        )
        
        if response.status_code != 200:
            return None
        
        return response.json()
    except Exception:
        return None


def extract_sites(search_results, facility_name: str = ''):
    """æ¤œç´¢çµæœã‹ã‚‰è‡ªç¤¾HPã¨OTAã‚µã‚¤ãƒˆã‚’åˆ†ã‘ã¦æŠ½å‡ºï¼ˆå³æ ¼ãªåˆ¤å®šï¼‰"""
    result = {
        'official_site': None,
        'ota_sites': []
    }
    
    if not search_results or 'web' not in search_results:
        return result
    
    if 'results' not in search_results['web'] or not search_results['web']['results']:
        return result
    
    results = search_results['web']['results']
    facility_name_lower = facility_name.lower().replace(' ', '').replace('ã€€', '')
    
    for item in results:
        url = item.get('url', '')
        title = item.get('title', '')
        description = item.get('description', '')
        
        if not url:
            continue
        
        # SNSãƒ»ãã®ä»–é™¤å¤–ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’ã‚¹ã‚­ãƒƒãƒ—
        if is_excluded_domain(url):
            continue
        
        # OTAãƒ‰ãƒ¡ã‚¤ãƒ³ã‹ãƒã‚§ãƒƒã‚¯
        if is_ota_domain(url):
            if url not in result['ota_sites']:
                result['ota_sites'].append(url)
            continue
        
        # è‡ªç¤¾HPã®å³æ ¼ãªåˆ¤å®š
        # 1. ã‚¿ã‚¤ãƒˆãƒ«ã‚„èª¬æ˜æ–‡ã«ã€Œå…¬å¼ã€ã€Œã‚ªãƒ•ã‚£ã‚·ãƒ£ãƒ«ã€ãŒå«ã¾ã‚Œã‚‹ã‹
        text_to_check = (title + ' ' + description).lower()
        has_official_keyword = (
            'å…¬å¼' in text_to_check or 
            'ã‚ªãƒ•ã‚£ã‚·ãƒ£ãƒ«' in text_to_check or 
            'official' in text_to_check
        )
        
        # 2. æ–½è¨­åãŒãƒ‰ãƒ¡ã‚¤ãƒ³ã‚„URLã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹ï¼ˆç°¡æ˜“ãƒã‚§ãƒƒã‚¯ï¼‰
        domain = extract_domain(url)
        url_lower = url.lower()
        has_facility_name = False
        if facility_name_lower:
            # æ–½è¨­åã®ä¸»è¦éƒ¨åˆ†ï¼ˆæœ€åˆã®3æ–‡å­—ä»¥ä¸Šï¼‰ãŒãƒ‰ãƒ¡ã‚¤ãƒ³ã«å«ã¾ã‚Œã‚‹ã‹
            facility_keywords = [
                facility_name_lower[:min(5, len(facility_name_lower))],
                facility_name_lower.replace('ãƒšãƒ³ã‚·ãƒ§ãƒ³', '').replace('æ°‘å®¿', '').replace('ãƒ›ãƒ†ãƒ«', '').strip()[:min(5, len(facility_name_lower))]
            ]
            for keyword in facility_keywords:
                if len(keyword) >= 3 and keyword in domain:
                    has_facility_name = True
                    break
        
        # è‡ªç¤¾HPã¨ã—ã¦æ¡ç”¨ã™ã‚‹æ¡ä»¶ï¼ˆå³æ ¼ï¼‰
        # æ¡ä»¶1: ã€Œå…¬å¼ã€ã€Œã‚ªãƒ•ã‚£ã‚·ãƒ£ãƒ«ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚‹
        # æ¡ä»¶2: æ–½è¨­åãŒãƒ‰ãƒ¡ã‚¤ãƒ³ã«å«ã¾ã‚Œã¦ã„ã‚‹
        # ã©ã¡ã‚‰ã‹ä¸€æ–¹ã§ã‚‚æº€ãŸã›ã°è‡ªç¤¾HPã¨åˆ¤å®šï¼ˆãŸã ã—ã€ã‚ˆã‚Šå³æ ¼ã«ã™ã‚‹å ´åˆã¯ä¸¡æ–¹ã‚’æº€ãŸã™å¿…è¦ãŒã‚ã‚‹ï¼‰
        if has_official_keyword or has_facility_name:
            if not result['official_site']:
                result['official_site'] = url
        # ã©ã¡ã‚‰ã®æ¡ä»¶ã‚‚æº€ãŸã•ãªã„å ´åˆã¯ã€OTAã‚µã‚¤ãƒˆã¨ã—ã¦æ‰±ã‚ãšã«ã‚¹ã‚­ãƒƒãƒ—
        # ï¼ˆè‡ªç¤¾HPã¨ã—ã¦æ¡ç”¨ã—ãªã„ï¼‰
    
    return result


def search_sites(facility_name: str, api_key: str):
    """å±‹å·ã‹ã‚‰è‡ªç¤¾HPã¨OTAã‚µã‚¤ãƒˆã‚’æ¤œç´¢"""
    best_result = {
        'official_site': None,
        'ota_sites': []
    }
    
    # å„æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’é †ç•ªã«è©¦ã™
    for query_func in SEARCH_QUERIES:
        query = query_func(facility_name)
        search_results = search_brave_api(query, api_key)
        extracted = extract_sites(search_results, facility_name)
        
        # è‡ªç¤¾HPãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã¯çµ‚äº†
        if extracted['official_site']:
            return {
                'official_site': extracted['official_site'],
                'ota_sites': list(set(best_result['ota_sites'] + extracted['ota_sites']))
            }
        
        # OTAã‚µã‚¤ãƒˆã‚’è“„ç©
        best_result['ota_sites'].extend(extracted['ota_sites'])
        
        # APIåˆ¶é™ã‚’è€ƒæ…®ã—ã¦å°‘ã—å¾…æ©Ÿ
        time.sleep(1.0)
    
    # OTAã‚µã‚¤ãƒˆã®é‡è¤‡ã‚’é™¤å»
    best_result['ota_sites'] = list(set(best_result['ota_sites']))
    
    return best_result


def main():
    st.title("ğŸ¨ å®¿æ³Šæ–½è¨­å…¬å¼ã‚µã‚¤ãƒˆæ¤œç´¢ãƒ„ãƒ¼ãƒ«")
    st.markdown("---")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼: è¨­å®š
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")
        
        # APIã‚­ãƒ¼å…¥åŠ›
        api_key = st.text_input(
            "Brave Search APIã‚­ãƒ¼",
            type="password",
            help="Brave Search APIã®ã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
        )
        
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ã‚‚å–å¾—ã‚’è©¦ã¿ã‚‹
        if not api_key:
            api_key = os.getenv('BRAVE_API_KEY', '')
        
        # å‡¦ç†ä»¶æ•°åˆ¶é™
        limit_count = st.number_input(
            "å‡¦ç†ä»¶æ•°ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰",
            min_value=1,
            max_value=1000,
            value=10,
            help="å‡¦ç†ã™ã‚‹ä»¶æ•°ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ï¼ˆãƒ†ã‚¹ãƒˆæ™‚ã¯å°‘ãªã‚ã«è¨­å®šï¼‰"
        )
        
        # APIå‘¼ã³å‡ºã—é–“éš”
        api_delay = st.slider(
            "APIå‘¼ã³å‡ºã—é–“éš”ï¼ˆç§’ï¼‰",
            min_value=0.5,
            max_value=5.0,
            value=1.0,
            step=0.5,
            help="APIå‘¼ã³å‡ºã—ã®é–“éš”ã‚’è¨­å®šï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼‰"
        )
    
    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
    st.header("ğŸ“¤ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    
    # CSVå½¢å¼ã®èª¬æ˜
    with st.expander("ğŸ“‹ CSVãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã«ã¤ã„ã¦", expanded=False):
        st.markdown("""
        **å…¥åŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼:**
        - **Aåˆ—ï¼ˆ1åˆ—ç›®ï¼‰: å±‹å·** - å®¿æ³Šæ–½è¨­ã®åå‰ï¼ˆå¿…é ˆï¼‰
        - ä»–ã®ã‚«ãƒ©ãƒ ï¼ˆé›»è©±ç•ªå·ã€website_urlãªã©ï¼‰ã¯ä»»æ„ã§ã™
        
        **å‡ºåŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼:**
        - **Aåˆ—: å±‹å·** - æ–½è¨­å
        - **Båˆ—: è‡ªç¤¾HP** - è¦‹ã¤ã‹ã£ãŸè‡ªç¤¾ã®å…¬å¼ã‚µã‚¤ãƒˆURLï¼ˆè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ç©ºæ¬„ï¼‰
        - **Cåˆ—: ä»–OTAãªã©ã®ã‚µã‚¤ãƒˆ** - OTAã‚µã‚¤ãƒˆãªã©ã®URLï¼ˆè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ç©ºæ¬„ã€è¤‡æ•°ã‚ã‚‹å ´åˆã¯ã‚»ãƒŸã‚³ãƒ­ãƒ³åŒºåˆ‡ã‚Šï¼‰
        """)
    
    uploaded_file = st.file_uploader(
        "CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
        type=['csv'],
        help="å¿…é ˆã‚«ãƒ©ãƒ : å±‹å·ï¼ˆAåˆ—ï¼‰"
    )
    
    if uploaded_file is not None:
        try:
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
            df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
            
            # å¿…é ˆã‚«ãƒ©ãƒ ã®ç¢ºèªï¼ˆAåˆ—ç›®ã‚’ç¢ºèªï¼‰
            first_column = df.columns[0]
            if 'å±‹å·' not in first_column and 'å±‹å·' not in df.columns:
                # Aåˆ—ã®å€¤ã‚’ã€Œå±‹å·ã€ã¨ã—ã¦æ‰±ã†
                df = df.rename(columns={first_column: 'å±‹å·'})
            
            # å±‹å·ã‚«ãƒ©ãƒ ã®ç¢ºèª
            if 'å±‹å·' not in df.columns:
                st.error("âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ã®Aåˆ—ï¼ˆ1åˆ—ç›®ï¼‰ã«ã€Œå±‹å·ã€ã‚«ãƒ©ãƒ ãŒå¿…è¦ã§ã™")
                st.info("ç¾åœ¨ã®ã‚«ãƒ©ãƒ : " + ", ".join(df.columns.tolist()))
            else:
                st.success(f"âœ… {len(df)}ä»¶ã®æ–½è¨­ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                with st.expander("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", expanded=False):
                    st.dataframe(df.head(10))
                
                # å®Ÿè¡Œãƒœã‚¿ãƒ³
                if not api_key or api_key == "":
                    st.warning("âš ï¸ APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®šï¼‰")
                else:
                    if st.button("ğŸš€ æ¤œç´¢å‡¦ç†ã‚’é–‹å§‹", type="primary", use_container_width=True):
                        # å‡¦ç†ä»¶æ•°ã‚’åˆ¶é™
                        df_processed = df.head(limit_count).copy()
                        
                        # çµæœã‚«ãƒ©ãƒ ã®åˆæœŸåŒ–
                        if 'è‡ªç¤¾HP' in df_processed.columns:
                            df_processed = df_processed.drop(columns=['è‡ªç¤¾HP'])
                        if 'ä»–OTAãªã©ã®ã‚µã‚¤ãƒˆ' in df_processed.columns:
                            df_processed = df_processed.drop(columns=['ä»–OTAãªã©ã®ã‚µã‚¤ãƒˆ'])
                        
                        df_processed['è‡ªç¤¾HP'] = ''
                        df_processed['ä»–OTAãªã©ã®ã‚µã‚¤ãƒˆ'] = ''
                        
                        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        
                        total_count = len(df_processed)
                        
                        # å„æ–½è¨­ã«ã¤ã„ã¦æ¤œç´¢ãƒ»åˆ¤å®šã‚’å®Ÿè¡Œ
                        for idx, (index, row) in enumerate(df_processed.iterrows()):
                            facility_name = str(row['å±‹å·'])
                            
                            # é€²æ—è¡¨ç¤º
                            progress = (idx + 1) / total_count
                            progress_bar.progress(progress)
                            status_text.text(f"å‡¦ç†ä¸­: {idx + 1}/{total_count} - {facility_name}")
                            
                            try:
                                # æ¤œç´¢å®Ÿè¡Œ
                                sites = search_sites(facility_name, api_key)
                                
                                # çµæœã‚’è¨˜éŒ²
                                df_processed.at[index, 'è‡ªç¤¾HP'] = sites['official_site'] or ''
                                df_processed.at[index, 'ä»–OTAãªã©ã®ã‚µã‚¤ãƒˆ'] = '; '.join(sites['ota_sites']) if sites['ota_sites'] else ''
                                
                            except Exception as e:
                                st.warning(f"âš ï¸ ã‚¨ãƒ©ãƒ¼ ({facility_name}): {e}")
                                df_processed.at[index, 'è‡ªç¤¾HP'] = ''
                                df_processed.at[index, 'ä»–OTAãªã©ã®ã‚µã‚¤ãƒˆ'] = ''
                            
                            # APIå‘¼ã³å‡ºã—é–“éš”
                            if idx < total_count - 1:
                                time.sleep(api_delay)
                        
                        # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                        progress_bar.progress(1.0)
                        status_text.text("âœ… å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                        
                        # çµæœè¡¨ç¤º
                        st.header("ğŸ“Š æ¤œç´¢çµæœ")
                        
                        # ã‚µãƒãƒªãƒ¼
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            hp_count = (df_processed['è‡ªç¤¾HP'] != '').sum()
                            st.metric("è‡ªç¤¾HPã‚ã‚Š", hp_count)
                        with col2:
                            ota_count = (df_processed['ä»–OTAãªã©ã®ã‚µã‚¤ãƒˆ'] != '').sum()
                            st.metric("OTAã‚µã‚¤ãƒˆã‚ã‚Š", ota_count)
                        with col3:
                            no_site = ((df_processed['è‡ªç¤¾HP'] == '') & (df_processed['ä»–OTAãªã©ã®ã‚µã‚¤ãƒˆ'] == '')).sum()
                            st.metric("ã‚µã‚¤ãƒˆãªã—", no_site)
                        
                        # çµæœãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆAåˆ—: å±‹å·ã€Båˆ—: è‡ªç¤¾HPã€Cåˆ—: ä»–OTAãªã©ã®ã‚µã‚¤ãƒˆã®ã¿è¡¨ç¤ºï¼‰
                        result_df = df_processed[['å±‹å·', 'è‡ªç¤¾HP', 'ä»–OTAãªã©ã®ã‚µã‚¤ãƒˆ']].copy()
                        st.dataframe(result_df, use_container_width=True)
                        
                        # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                        csv_output = result_df.to_csv(index=False, encoding='utf-8-sig')
                        st.download_button(
                            label="ğŸ“¥ çµæœã‚’CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=csv_output,
                            file_name="æ¤œç´¢çµæœ.csv",
                            mime="text/csv",
                            use_container_width=True
                        )
                        
        except Exception as e:
            st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.exception(e)


if __name__ == '__main__':
    main()
