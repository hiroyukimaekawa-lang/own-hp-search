"""
ãƒ†ãƒ¬ã‚¢ãƒå–¶æ¥­ç”¨æ–½è¨­åˆ¤å®šã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆSerpAPIç‰ˆï¼‰
Streamlitç‰ˆ
"""

import streamlit as st
import os
import re
import csv
import io
from typing import List, Dict, Optional
from dotenv import load_dotenv
import requests
from urllib.parse import urlparse
import time
from serpapi import GoogleSearch

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ãƒ†ãƒ¬ã‚¢ãƒå–¶æ¥­å¯¾è±¡ãƒªã‚¹ãƒˆä½œæˆãƒ„ãƒ¼ãƒ«",
    page_icon="ğŸ¨",
    layout="wide"
)

# APIè¨­å®š
SERPAPI_KEY = os.getenv("SERPAPI_KEY")

# ç°¡æ˜“HPã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒªã‚¹ãƒˆ
SIMPLE_HP_DOMAINS_FREE = [
    "wixsite.com",
    "wordpress.com",
    "canva.site",
    "peraichi.com",
    "jimdosite.com",
]

# é›¢å³¶ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
ISLAND_KEYWORDS = [
    "é›¢å³¶", "å³¶", "å¥„ç¾", "æ²–æ°¸è‰¯éƒ¨", "ä¸è«–", "ä¹…ç±³å³¶", "å®®å¤å³¶", "çŸ³å£å³¶",
    "è¥¿è¡¨å³¶", "ç«¹å¯Œå³¶", "å°æµœå³¶", "æ³¢ç…§é–“å³¶", "ä¸é‚£å›½å³¶", "ä¼Šæ±Ÿå³¶", "åº§é–“å‘³å³¶",
    "æ¸¡å˜‰æ•·å³¶", "ç²Ÿå›½å³¶", "ä¼Šå¹³å±‹å³¶", "ä¼Šæ˜¯åå³¶", "åŒ—å¤§æ±å³¶", "å—å¤§æ±å³¶",
    "å¤šè‰¯é–“å³¶", "æ°´ç´å³¶", "å¤å®‡åˆ©å³¶", "ç€¬åº•å³¶", "ä¼Šè¨ˆå³¶", "å®®åŸå³¶", "å¹³å®‰åº§å³¶",
    "æµœæ¯”å˜‰å³¶", "æ´¥å …å³¶", "ä¹…é«˜å³¶", "å¥¥æ­¦å³¶", "ç€¬é•·å³¶",
]


def extract_prefecture(address: str) -> str:
    """ä½æ‰€ã‹ã‚‰éƒ½é“åºœçœŒã‚’æŠ½å‡º"""
    if not address:
        return ""
    
    prefecture_pattern = r"(åŒ—æµ·é“|é’æ£®çœŒ|å²©æ‰‹çœŒ|å®®åŸçœŒ|ç§‹ç”°çœŒ|å±±å½¢çœŒ|ç¦å³¶çœŒ|èŒ¨åŸçœŒ|æ ƒæœ¨çœŒ|ç¾¤é¦¬çœŒ|åŸ¼ç‰çœŒ|åƒè‘‰çœŒ|æ±äº¬éƒ½|ç¥å¥ˆå·çœŒ|æ–°æ½ŸçœŒ|å¯Œå±±çœŒ|çŸ³å·çœŒ|ç¦äº•çœŒ|å±±æ¢¨çœŒ|é•·é‡çœŒ|å²é˜œçœŒ|é™å²¡çœŒ|æ„›çŸ¥çœŒ|ä¸‰é‡çœŒ|æ»‹è³€çœŒ|äº¬éƒ½åºœ|å¤§é˜ªåºœ|å…µåº«çœŒ|å¥ˆè‰¯çœŒ|å’Œæ­Œå±±çœŒ|é³¥å–çœŒ|å³¶æ ¹çœŒ|å²¡å±±çœŒ|åºƒå³¶çœŒ|å±±å£çœŒ|å¾³å³¶çœŒ|é¦™å·çœŒ|æ„›åª›çœŒ|é«˜çŸ¥çœŒ|ç¦å²¡çœŒ|ä½è³€çœŒ|é•·å´çœŒ|ç†Šæœ¬çœŒ|å¤§åˆ†çœŒ|å®®å´çœŒ|é¹¿å…å³¶çœŒ|æ²–ç¸„çœŒ)"
    
    match = re.search(prefecture_pattern, address)
    if match:
        return match.group(1)
    
    return ""


def is_island(address: str) -> bool:
    """ä½æ‰€ã‹ã‚‰é›¢å³¶ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
    if not address:
        return False
    
    address_lower = address.lower()
    for keyword in ISLAND_KEYWORDS:
        if keyword in address_lower:
            return True
    
    return False


def is_simple_hp_free(url: str) -> bool:
    """URLãŒç°¡æ˜“HPã‚µãƒ¼ãƒ“ã‚¹ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
    if not url:
        return False

    try:
        parsed = urlparse(url)
        domain = parsed.netloc.lower().replace("www.", "")
        for simple_domain in SIMPLE_HP_DOMAINS_FREE:
            if simple_domain in domain:
                return True
        return False
    except Exception:
        return False


def check_website_technology_free(url: str) -> bool:
    """URLã®HTMLã‚’å–å¾—ã—ã¦ã€ç°¡æ˜“HPã‚µãƒ¼ãƒ“ã‚¹ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
    if not url:
        return False

    if is_simple_hp_free(url):
        return True

    try:
        response = requests.get(url, timeout=10, headers={
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        })

        if response.status_code == 200:
            html_content = response.text.lower()

            if "wp-content" in html_content or "wordpress" in html_content:
                return True
            if "wixsite.com" in html_content or "wixstatic.com" in html_content:
                return True
            if "canva.site" in html_content or "canva.com" in html_content:
                return True
            if "peraichi.com" in html_content:
                return True
            if "jimdosite.com" in html_content or "jimdo" in html_content:
                return True

    except Exception:
        pass

    return False


def search_serpapi(facility_name: str, api_key: str) -> Optional[Dict]:
    """SerpAPIã‚’ä½¿ç”¨ã—ã¦æ–½è¨­æƒ…å ±ã‚’å–å¾—"""
    if not api_key:
        return None
    
    query = f"{facility_name}"
    
    try:
        params = {
            "q": query,
            "api_key": api_key,
            "engine": "google",
            "hl": "ja",
            "gl": "jp",
            "location": "Japan",
        }
        
        search = GoogleSearch(params)
        results = search.get_dict()
        
        website = ""
        address = ""
        
        # æ¤œç´¢çµæœã‹ã‚‰Googleãƒ“ã‚¸ãƒã‚¹ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã®æƒ…å ±ã‚’å–å¾—
        if "local_results" in results:
            local_results = results["local_results"]
            if local_results and len(local_results) > 0:
                local_result = local_results[0]
                if "website" in local_result:
                    website = local_result["website"]
                if "address" in local_result:
                    address = local_result["address"]
        
        # ãƒ­ãƒ¼ã‚«ãƒ«çµæœãŒãªã„å ´åˆã€é€šå¸¸ã®æ¤œç´¢çµæœã‹ã‚‰æ¢ã™
        if not website and "organic_results" in results:
            organic_results = results["organic_results"]
            for result in organic_results:
                link = result.get("link", "")
                snippet = result.get("snippet", "")
                
                if "maps.google.com" in link or "google.com/maps" in link:
                    if snippet:
                        prefecture_match = re.search(r"([éƒ½é“åºœçœŒ].*?[å¸‚åŒºç”ºæ‘].*?[0-9])", snippet)
                        if prefecture_match:
                            address = prefecture_match.group(1)
                    break
        
        return {"website": website, "address": address}
    
    except Exception as e:
        st.error(f"SerpAPIæ¤œç´¢ã‚¨ãƒ©ãƒ¼ ({facility_name}): {e}")
        return None


def judge_target_serpapi(facility_name: str, website: str, address: str) -> Dict:
    """æ–½è¨­ãŒå–¶æ¥­å¯¾è±¡ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
    prefecture = extract_prefecture(address)
    
    # æ²–ç¸„çœŒãƒã‚§ãƒƒã‚¯
    if prefecture == "æ²–ç¸„çœŒ":
        return {
            "facility_name": facility_name,
            "website": "",
            "is_target": "ã„ã„ãˆ",
            "prefecture": prefecture,
            "reason": "æ²–ç¸„çœŒã®ãŸã‚é™¤å¤–",
        }
    
    # é›¢å³¶ãƒã‚§ãƒƒã‚¯
    if is_island(address):
        return {
            "facility_name": facility_name,
            "website": "",
            "is_target": "ã„ã„ãˆ",
            "prefecture": prefecture,
            "reason": "é›¢å³¶ã®ãŸã‚é™¤å¤–",
        }
    
    # ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆãŒå­˜åœ¨ã—ãªã„å ´åˆ
    if not website or website.strip() == "":
        return {
            "facility_name": facility_name,
            "website": "",
            "is_target": "ã¯ã„",
            "prefecture": prefecture,
            "reason": "å…¬å¼HPãªã—",
        }
    
    # ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆãŒå­˜åœ¨ã™ã‚‹å ´åˆã€ç°¡æ˜“HPã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
    is_simple = check_website_technology_free(website)
    
    if is_simple:
        return {
            "facility_name": facility_name,
            "website": website,
            "is_target": "ã¯ã„",
            "prefecture": prefecture,
            "reason": "ç°¡æ˜“HPä½¿ç”¨",
        }
    else:
        return {
            "facility_name": facility_name,
            "website": website,
            "is_target": "ã„ã„ãˆ",
            "prefecture": prefecture,
            "reason": "å…¬å¼HPã‚ã‚Š",
        }


def process_csv_file(uploaded_file, api_key: str):
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦çµæœã‚’è¿”ã™"""
    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    try:
        csv_content = uploaded_file.read().decode("utf-8-sig")
    except UnicodeDecodeError:
        uploaded_file.seek(0)
        csv_content = uploaded_file.read().decode("shift_jis")
    
    reader = csv.reader(io.StringIO(csv_content))
    rows = list(reader)
    
    if len(rows) < 1:
        st.error("CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™")
        return None
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
    data_rows = rows[1:] if len(rows) > 1 else []
    
    # Aåˆ—ï¼ˆæ–½è¨­åï¼‰ã‚’æŠ½å‡º
    facilities = []
    for row in data_rows:
        if len(row) > 0 and row[0].strip():
            facilities.append(row[0].strip())
    
    if not facilities:
        st.error("æ–½è¨­åãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return None
    
    return facilities


# ãƒ¡ã‚¤ãƒ³UI
st.title("ğŸ¨ ãƒ†ãƒ¬ã‚¢ãƒå–¶æ¥­å¯¾è±¡ãƒªã‚¹ãƒˆä½œæˆãƒ„ãƒ¼ãƒ«")
st.markdown("### æ–½è¨­åãƒªã‚¹ãƒˆã‹ã‚‰å–¶æ¥­å¯¾è±¡ã‚’è‡ªå‹•åˆ¤å®š")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    serpapi_key = st.text_input(
        "SerpAPIã‚­ãƒ¼",
        value=SERPAPI_KEY or "7f319edbccde7eaa91d73398346def20ddb65e7f0f13cedc32ba60b4b7ba762f",
        type="password",
        help="SerpAPIã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã«å¿…è¦ã§ã™ï¼ˆç„¡æ–™ãƒ—ãƒ©ãƒ³: æœˆ100å›ã¾ã§åˆ©ç”¨å¯èƒ½ï¼‰"
    )
    
    st.markdown("---")
    st.markdown("### ğŸ“‹ ä½¿ã„æ–¹")
    st.markdown("""
    1. SerpAPIã‚­ãƒ¼ã‚’å…¥åŠ›ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§è¨­å®šæ¸ˆã¿ï¼‰
    2. CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    3. ã€Œå‡¦ç†ã‚’é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
    4. çµæœã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    """)
    
    st.markdown("---")
    st.markdown("### ğŸ“ CSVå½¢å¼")
    st.markdown("**å…¥åŠ›:** Aåˆ—ã«æ–½è¨­åï¼ˆå±‹å·ï¼‰")
    st.markdown("**å‡ºåŠ›:** æ–½è¨­åã€HP URLã€å–¶æ¥­å¯¾è±¡ã€éƒ½é“åºœçœŒ")

# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
st.markdown("---")

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader(
    "CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
    type=["csv"],
    help="Aåˆ—ã«æ–½è¨­åï¼ˆå±‹å·ï¼‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
)

if uploaded_file is not None:
    if st.button("ğŸš€ å‡¦ç†ã‚’é–‹å§‹", type="primary", use_container_width=True):
        # APIã‚­ãƒ¼ã®ãƒã‚§ãƒƒã‚¯
        if not serpapi_key:
            st.error("SerpAPIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            st.stop()
        
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
        facilities = process_csv_file(uploaded_file, serpapi_key)
        
        if facilities:
            # é€²æ—ãƒãƒ¼
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # çµæœæ ¼ç´ç”¨
            results = []
            total = len(facilities)
            
            # å„æ–½è¨­ã«ã¤ã„ã¦å‡¦ç†
            for idx, facility_name in enumerate(facilities):
                status_text.text(f"å‡¦ç†ä¸­: {idx + 1}/{total} - {facility_name}")
                progress_bar.progress((idx + 1) / total)
                
                # SerpAPIã§æ¤œç´¢å®Ÿè¡Œ
                place_info = search_serpapi(facility_name, serpapi_key)
                website = place_info.get("website", "") if place_info else ""
                address = place_info.get("address", "") if place_info else ""
                
                # åˆ¤å®šå®Ÿè¡Œ
                result = judge_target_serpapi(facility_name, website, address)
                results.append(result)
                
                # APIåˆ¶é™å¯¾ç­–
                if idx < total - 1:
                    time.sleep(1.0)
            
            # çµæœã‚’é›†è¨ˆ
            total_count = len(results)
            target_count = sum(1 for result in results if result.get("is_target") == "ã¯ã„")
            non_target_count = total_count - target_count
            
            # çµæœè¡¨ç¤º
            st.success(f"âœ… å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            
            # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ç·ä»¶æ•°", f"{total_count}ä»¶")
            with col2:
                st.metric("å–¶æ¥­å¯¾è±¡", f"{target_count}ä»¶", delta=f"{target_count/total_count*100:.1f}%")
            with col3:
                st.metric("éå¯¾è±¡", f"{non_target_count}ä»¶")
            
            # CSVã‚’ç”Ÿæˆ
            output = io.StringIO()
            writer = csv.writer(output)
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼
            writer.writerow(["æ–½è¨­å", "å…¬å¼HPã®URL", "å–¶æ¥­å¯¾è±¡ã‹", "éƒ½é“åºœçœŒå"])
            
            # ãƒ‡ãƒ¼ã‚¿
            for result in results:
                writer.writerow([
                    result["facility_name"],
                    result.get("website", ""),
                    result.get("is_target", ""),
                    result.get("prefecture", ""),
                ])
            
            csv_content = output.getvalue()
            
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            st.download_button(
                label="ğŸ“¥ çµæœã‚’CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv_content.encode("utf-8-sig"),
                file_name="å–¶æ¥­å¯¾è±¡ãƒªã‚¹ãƒˆ.csv",
                mime="text/csv",
                use_container_width=True
            )
            
            # çµæœãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
            st.markdown("---")
            st.markdown("### ğŸ“Š å‡¦ç†çµæœ")
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›ã—ã¦è¡¨ç¤º
            import pandas as pd
            df = pd.DataFrame(results)
            df_display = df[["facility_name", "website", "is_target", "prefecture"]]
            df_display.columns = ["æ–½è¨­å", "å…¬å¼HPã®URL", "å–¶æ¥­å¯¾è±¡ã‹", "éƒ½é“åºœçœŒå"]
            st.dataframe(df_display, use_container_width=True, height=400)
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
            st.session_state['results'] = results
            st.session_state['csv_content'] = csv_content

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("### ğŸ“– å–¶æ¥­å¯¾è±¡ã®åˆ¤å®šæ¡ä»¶")
st.markdown("""
- âœ… **å–¶æ¥­å¯¾è±¡ã€Œã¯ã„ã€**: å…¬å¼HPãŒå­˜åœ¨ã—ãªã„ã€ã¾ãŸã¯ç°¡æ˜“HPã‚µãƒ¼ãƒ“ã‚¹ï¼ˆWordPress/Wix/Canva/ãƒšãƒ©ã‚¤ãƒ/Jimdoï¼‰ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹
- âŒ **å–¶æ¥­å¯¾è±¡ã€Œã„ã„ãˆã€**: å…¬å¼HPãŒã‚ã‚Šã€ã‹ã¤æ²–ç¸„çœŒãƒ»é›¢å³¶ã§ã¯ãªã„
- ğŸš« **é™¤å¤–**: æ²–ç¸„çœŒã¾ãŸã¯é›¢å³¶ã®æ–½è¨­ã¯è‡ªå‹•çš„ã«é™¤å¤–ã•ã‚Œã¾ã™
""")

