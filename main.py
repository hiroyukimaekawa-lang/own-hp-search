"""
å®¿æ³Šæ–½è¨­ã®å…¬å¼ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸æœ‰ç„¡ã‚’è‡ªå‹•åˆ¤å®šã™ã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³

å…¥åŠ›: ç„¡é¡Œã®ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ (14).xlsxï¼ˆå±‹å·ã€é›»è©±ç•ªå·ï¼‰
å‡ºåŠ›: ç„¡é¡Œã®ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ (14).xlsxï¼ˆä¸€ç•ªå³ã®åˆ—ã«åˆ¤å®šçµæœã‚’è¿½è¨˜ï¼‰
"""

import os
import time
import pandas as pd
import requests
from urllib.parse import urlparse
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()
API_KEY = os.getenv('BRAVE_API_KEY')
SEARCH_ENDPOINT = 'https://api.search.brave.com/res/v1/web/search'

# OTAãƒ‰ãƒ¡ã‚¤ãƒ³ãƒªã‚¹ãƒˆï¼ˆå…¬å¼HPãªã—ã¨åˆ¤å®šã™ã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³ï¼‰
OTA_DOMAINS = [
    'rakuten.co.jp',
    'jalan.net',
    'booking.com',
    'expedia.com',
    'expedia.co.jp',
    'ikyu.com',
    'agoda.com'
]

# APIå‘¼ã³å‡ºã—é–“éš”ï¼ˆç§’ï¼‰ - ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’é¿ã‘ã‚‹ãŸã‚
API_DELAY = 1.0


def load_excel(file_path):
    """
    Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    
    Args:
        file_path (str): èª­ã¿è¾¼ã‚€Excelãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        
    Returns:
        pd.DataFrame: èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã€ã‚¨ãƒ©ãƒ¼æ™‚ã¯None
    """
    try:
        print(f"ğŸ“‚ Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­: {file_path}")
        df = pd.read_excel(file_path)
        
        # å¿…é ˆã‚«ãƒ©ãƒ ã®å­˜åœ¨ç¢ºèª
        required_columns = ['å±‹å·', 'é›»è©±ç•ªå·']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: å¿…é ˆã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_columns}")
            return None
        
        print(f"âœ… {len(df)}ä»¶ã®æ–½è¨­ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        return df
        
    except FileNotFoundError:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        return None
    except Exception as e:
        print(f"âŒ Excelãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None


def search_official_site(query):
    """
    Brave Search APIã‚’ä½¿ç”¨ã—ã¦æ¤œç´¢ã‚’å®Ÿè¡Œ
    
    Args:
        query (str): æ¤œç´¢ã‚¯ã‚¨ãƒª
        
    Returns:
        dict: APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®JSONãƒ‡ãƒ¼ã‚¿ã€ã‚¨ãƒ©ãƒ¼æ™‚ã¯None
        
    Brave Search APIãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ :
        {
            "web": {
                "results": [
                    {
                        "url": "https://example.com",
                        "title": "ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«",
                        "description": "ãƒšãƒ¼ã‚¸ã®èª¬æ˜æ–‡"
                    },
                    ...
                ]
            }
        }
    """
    headers = {
        'Accept': 'application/json',
        'X-Subscription-Token': API_KEY
    }
    params = {
        'q': query,
        'count': 10  # æœ€å¤§10ä»¶ã®æ¤œç´¢çµæœã‚’å–å¾—
    }
    
    try:
        response = requests.get(SEARCH_ENDPOINT, headers=headers, params=params, timeout=10)
        
        # ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®è©³ç´°ã‚’ç¢ºèª
        if response.status_code != 200:
            error_detail = response.text
            print(f"âš ï¸  APIã‚¨ãƒ©ãƒ¼ ({response.status_code}): {error_detail[:200]}")
            return None
        
        response.raise_for_status()
        return response.json()
        
    except requests.exceptions.RequestException as e:
        print(f"âš ï¸  æ¤œç´¢APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
        if hasattr(e, 'response') and e.response is not None:
            print(f"   ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {e.response.text[:200]}")
        return None
    except Exception as e:
        print(f"âš ï¸  æ¤œç´¢ä¸­ã«äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None


def judge_hp_existence(search_results):
    """
    æ¤œç´¢çµæœã‹ã‚‰å…¬å¼HPã®æœ‰ç„¡ã‚’åˆ¤å®š
    
    åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯:
    1. ç‹¬è‡ªãƒ‰ãƒ¡ã‚¤ãƒ³ï¼ˆOTAä»¥å¤–ï¼‰ã§ã€Œå…¬å¼ã€ã€Œã‚ªãƒ•ã‚£ã‚·ãƒ£ãƒ«ã€ã‚’å«ã‚€ â†’ HPã‚ã‚Š
    2. ç‹¬è‡ªãƒ‰ãƒ¡ã‚¤ãƒ³ãŒ1ã¤ã§ã‚‚è¦‹ã¤ã‹ã‚Œã° â†’ HPã‚ã‚Š
    3. OTAã®ã¿ã®å ´åˆã¯ â†’ HPãªã—
    4. æ¤œç´¢çµæœãŒãªã„å ´åˆã¯ â†’ ä¸æ˜
    
    Args:
        search_results (dict): Brave Search APIã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹
        
    Returns:
        tuple: (HPæœ‰ç„¡, åˆ¤å®šç†ç”±, æ¤œå‡ºURL)
            - HPæœ‰ç„¡: 'ã‚ã‚Š' / 'ãªã—' / 'ä¸æ˜'
            - åˆ¤å®šç†ç”±: 'å…¬å¼ã‚µã‚¤ãƒˆæ¤œå‡º' / 'OTAã®ã¿' / 'æ¤œç´¢çµæœãªã—' / 'ä¸æ˜'
            - æ¤œå‡ºURL: åˆ¤å®šã«ä½¿ç”¨ã—ãŸURLï¼ˆè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯Noneï¼‰
    """
    if not search_results:
        return 'ä¸æ˜', 'æ¤œç´¢çµæœãªã—', None
    
    # APIãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ ã®ç¢ºèª
    if 'web' not in search_results:
        return 'ä¸æ˜', 'æ¤œç´¢çµæœãªã—', None
    
    if 'results' not in search_results['web'] or not search_results['web']['results']:
        return 'ä¸æ˜', 'æ¤œç´¢çµæœãªã—', None
    
    results = search_results['web']['results']
    ota_only = True  # OTAã®ã¿ã‹ã©ã†ã‹ã®ãƒ•ãƒ©ã‚°
    official_domain_found = None  # è¦‹ã¤ã‹ã£ãŸç‹¬è‡ªãƒ‰ãƒ¡ã‚¤ãƒ³ã®URL
    
    for result in results:
        url = result.get('url', '')
        title = result.get('title', '')
        description = result.get('description', '')
        
        if not url:
            continue
        
        # URLã‹ã‚‰ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’æŠ½å‡º
        try:
            parsed_url = urlparse(url)
            domain = parsed_url.netloc.replace('www.', '').lower()
        except Exception:
            continue
        
        # OTAãƒ‰ãƒ¡ã‚¤ãƒ³ã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
        is_ota = False
        for ota_domain in OTA_DOMAINS:
            if ota_domain in domain:
                is_ota = True
                break
        
        if is_ota:
            continue  # OTAãƒ‰ãƒ¡ã‚¤ãƒ³ã¯ã‚¹ã‚­ãƒƒãƒ—
        
        # OTAä»¥å¤–ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ãŒè¦‹ã¤ã‹ã£ãŸ
        ota_only = False
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã‚„èª¬æ˜æ–‡ã«ã€Œå…¬å¼ã€ã€Œã‚ªãƒ•ã‚£ã‚·ãƒ£ãƒ«ã€ãŒå«ã¾ã‚Œã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        text_to_check = (title + ' ' + description).lower()
        if 'å…¬å¼' in text_to_check or 'ã‚ªãƒ•ã‚£ã‚·ãƒ£ãƒ«' in text_to_check or 'official' in text_to_check:
            return 'ã‚ã‚Š', 'å…¬å¼ã‚µã‚¤ãƒˆæ¤œå‡º', url
        
        # ç‹¬è‡ªãƒ‰ãƒ¡ã‚¤ãƒ³ãŒè¦‹ã¤ã‹ã£ãŸãŒã€ã¾ã å…¬å¼ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯è¦‹ã¤ã‹ã£ã¦ã„ãªã„
        if official_domain_found is None:
            official_domain_found = url
    
    # åˆ¤å®šçµæœã®æ±ºå®š
    if ota_only:
        return 'ãªã—', 'OTAã®ã¿', None
    elif official_domain_found:
        return 'ã‚ã‚Š', 'å…¬å¼ã‚µã‚¤ãƒˆæ¤œå‡º', official_domain_found
    else:
        return 'ä¸æ˜', 'ä¸æ˜', None


def save_excel(df, file_path):
    """
    çµæœã‚’Excelãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    
    Args:
        df (pd.DataFrame): ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        file_path (str): ä¿å­˜å…ˆã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        
    Returns:
        bool: ä¿å­˜æˆåŠŸæ™‚Trueã€å¤±æ•—æ™‚False
    """
    try:
        df.to_excel(file_path, index=False)
        print(f"âœ… çµæœã‚’ {file_path} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
        return True
    except Exception as e:
        print(f"âŒ Excelãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return False


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    input_file = 'ç„¡é¡Œã®ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ (14).xlsx'
    output_file = 'ç„¡é¡Œã®ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ (14).xlsx'
    
    # APIã‚­ãƒ¼ã®ç¢ºèª
    if not API_KEY:
        print("âŒ ã‚¨ãƒ©ãƒ¼: BRAVE_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return
    
    # Excelãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    df = load_excel(input_file)
    if df is None:
        return
    
    # ãƒ†ã‚¹ãƒˆç”¨: æœ€åˆã®10ä»¶ã®ã¿å‡¦ç†
    TEST_MODE = True
    TEST_LIMIT = 10
    
    if TEST_MODE:
        df = df.head(TEST_LIMIT)
        print(f"âš ï¸  ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰: æœ€åˆã®{TEST_LIMIT}ä»¶ã®ã¿å‡¦ç†ã—ã¾ã™\n")
    
    # çµæœã‚«ãƒ©ãƒ åã‚’æ±ºå®šï¼ˆä¸€ç•ªå³ã®åˆ—ã«è¿½åŠ ï¼‰
    result_column = 'å…¬å¼HPæœ‰ç„¡'
    
    # æ—¢ã«çµæœã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯å‰Šé™¤ã—ã¦å†ä½œæˆ
    if result_column in df.columns:
        df = df.drop(columns=[result_column])
    
    # çµæœã‚«ãƒ©ãƒ ã®åˆæœŸåŒ–ï¼ˆä¸€ç•ªå³ã«è¿½åŠ ï¼‰
    df[result_column] = ''
    
    total_count = len(df)
    print(f"\nğŸ” {total_count}ä»¶ã®æ–½è¨­ã«ã¤ã„ã¦æ¤œç´¢ã‚’é–‹å§‹ã—ã¾ã™...\n")
    
    # å„æ–½è¨­ã«ã¤ã„ã¦æ¤œç´¢ãƒ»åˆ¤å®šã‚’å®Ÿè¡Œ
    for index, row in df.iterrows():
        facility_name = str(row['å±‹å·'])
        
        # æ¤œç´¢ã‚¯ã‚¨ãƒªã®ç”Ÿæˆï¼ˆåœ°åŸŸæƒ…å ±ãªã—ã§æ¤œç´¢ï¼‰
        query = f"{facility_name} å…¬å¼ã‚µã‚¤ãƒˆ"
        
        print(f"[{index + 1}/{total_count}] æ¤œç´¢ä¸­: {query}")
        
        # æ¤œç´¢å®Ÿè¡Œ
        search_results = search_official_site(query)
        
        # åˆ¤å®šå®Ÿè¡Œ
        hp_existence, reason, detected_url = judge_hp_existence(search_results)
        
        # çµæœã‚’ä¸€ç•ªå³ã®åˆ—ã«è¨˜éŒ²ï¼ˆã€Œâ‡¨ã¯ã„ã€ã¾ãŸã¯ã€Œãªã—â‡¨ã„ã„ãˆã€ã®å½¢å¼ï¼‰
        if hp_existence == 'ã‚ã‚Š':
            result_text = 'â‡¨ã¯ã„'
        elif hp_existence == 'ãªã—':
            result_text = 'ãªã—â‡¨ã„ã„ãˆ'
        else:
            result_text = ''  # ä¸æ˜ã®å ´åˆã¯ç©ºæ¬„
        
        df.at[index, result_column] = result_text
        
        print(f"  â†’ åˆ¤å®šçµæœ: {result_text} ({reason})")
        
        # APIå‘¼ã³å‡ºã—é–“éš”ã‚’ç©ºã‘ã‚‹ï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼‰
        if index < total_count - 1:  # æœ€å¾Œã®1ä»¶ã¯å¾…æ©Ÿä¸è¦
            time.sleep(API_DELAY)
    
    print(f"\nğŸ’¾ çµæœã‚’ä¿å­˜ä¸­...")
    
    # çµæœã®ä¿å­˜ï¼ˆå…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ãï¼‰
    if save_excel(df, output_file):
        print(f"\nâœ¨ å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print(f"   å…¥åŠ›: {input_file}")
        print(f"   å‡ºåŠ›: {output_file}")
        
        # çµæœã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
        summary = df[result_column].value_counts()
        print(f"\nğŸ“Š åˆ¤å®šçµæœã‚µãƒãƒªãƒ¼:")
        for status, count in summary.items():
            if status:  # ç©ºæ¬„ä»¥å¤–ã®ã¿è¡¨ç¤º
                print(f"   {status}: {count}ä»¶")
        if '' in summary:
            print(f"   ä¸æ˜: {summary['']}ä»¶")


if __name__ == '__main__':
    main()

